{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkSUOt4cTpNl"
      },
      "source": [
        "IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOLgv7QlTnp6"
      },
      "source": [
        "def load_libraries():\n",
        "  import pandas as pd\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from tensorflow.keras.utils import normalize,to_categorical\n",
        "  import tensorflow as tf\n",
        "  from tensorflow.keras.models import Sequential\n",
        "  from tensorflow.keras.layers import Dense, Dropout\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from tensorflow.keras.optimizers import Adam\n",
        "  from tensorflow.keras import regularizers\n",
        "  from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHgA1cStTuCu"
      },
      "source": [
        "DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhmTknauTvWu"
      },
      "source": [
        "def setup_data(file_name):\n",
        "  df = pd.read_csv(file_name).dropna()\n",
        "\n",
        "  X = df.drop(columns=\"label\")\n",
        "  y = df['label']\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
        "\n",
        "  X_train = normalize(X_train)\n",
        "  X_test = normalize(X_test)\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnLZtZHuVvr9"
      },
      "source": [
        "Build Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O_OX-zQV8qN"
      },
      "source": [
        "def build(num_of_layers,nodes_per_layer,activation_function,L2_lambda,Dropout_rate):\n",
        "  tf.keras.backend.clear_session()\n",
        "\n",
        "  List_of_models.append(Sequential())\n",
        "  model = List_of_models[-1]\n",
        "\n",
        "  random = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
        "  global num_input_nuerons, num_output_nuerons\n",
        "\n",
        "  model.add(  Dense(num_input_nuerons)   )\n",
        "  for i in range(num_of_layers):\n",
        "    model.add(Dense(units=nodes_per_layer, activation=activation_function,kernel_initializer=random, kernel_regularizer = regularizers.l2(L2_lambda)))\n",
        "    model.add(Dropout(Dropout_rate))\n",
        "\n",
        "  model.add(Dense(units= num_output_nuerons , activation='softmax' ,kernel_initializer=random))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0gYJ6tdG7XP"
      },
      "source": [
        "Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir5KFPb6G-eg"
      },
      "source": [
        "class CustumCallback(tf.keras.callbacks.Callback):\n",
        "  \n",
        "  min_accuracy = .9\n",
        "  counter = 0\n",
        "  previous_accuracy = 0\n",
        "  good_counter = 0\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    if logs.get(\"accuracy\") > self.min_accuracy:\n",
        "      self.good_counter+=1\n",
        "      if self.good_counter > 10:\n",
        "        print(f\"Accuracy consistently over {100*self.min_accuracy}%, training terminated.\")\n",
        "        self.model.stop_training = True\n",
        "    else:\n",
        "      self.good_counter = 0\n",
        "\n",
        "    if epoch == 1: \n",
        "      pass\n",
        "    elif self.previous_accuracy == logs.get(\"accuracy\"):\n",
        "      self.counter +=1\n",
        "    else:\n",
        "      self.counter = 0\n",
        "    \n",
        "    if self.counter == 10: \n",
        "      print(f\"This network reached a maximum accuracy at {logs.get('accuracy')} \")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "    self.previous_accuracy = logs.get(\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIVmhw5-Usi9"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4XKXdfaUu2d"
      },
      "source": [
        "def train():\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])\n",
        "  model.fit(X_train, y_train, epochs=1000, batch_size=len(X_train), callbacks = [CustumCallback()])\n",
        "\n",
        "  model.save(f'/content/drive/MyDrive/High School Ramaz/Meta-AI/Files/results/saved_model{Index_of_network}/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzWhirKEV_sN"
      },
      "source": [
        "Results of Nueral Netowrk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6HZwojAxTi8"
      },
      "source": [
        "def evaluateNN():\n",
        "  y_train1d = [list(x).index(max(x)) for x in y_train]\n",
        "  y_test1d = [list(x).index(max(x)) for x in y_test]\n",
        "\n",
        "  y_hat1 = [list(x).index(max(x)) for x in model.predict(X_train)]\n",
        "  training_accuracy = 100 * accuracy_score(y_train1d, y_hat1)\n",
        "  print(\"NN Training Accuracy:\", training_accuracy)\n",
        "  cm = tf.math.confusion_matrix(y_train1d, y_hat1)\n",
        "  print(cm)\n",
        "\n",
        "  y_hat = [list(x).index(max(x)) for x in model.predict(X_test)]\n",
        "  testing_accuracy = 100 * accuracy_score(y_test1d, y_hat)\n",
        "  print(\"NN Testing Accuracy:\",testing_accuracy) \n",
        "  cm1 = tf.math.confusion_matrix(y_test1d, y_hat)\n",
        "  print(cm1)\n",
        "\n",
        "  global Index_of_network\n",
        "  ALL_NETWORKS.append({'Testing accuracy':testing_accuracy, 'Training accuracy':training_accuracy})\n",
        "  Index_of_network += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYfNltv8oXfm"
      },
      "source": [
        "Change the NN based on Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54guyjPgoeUY"
      },
      "source": [
        "def analyze(num_of_layers,nodes_per_layer,activation_function,L2_lambda,Dropout_rate):\n",
        "  test_accuracy = ALL_NETWORKS[-1]['Testing accuracy']\n",
        "  train_accuracy = ALL_NETWORKS[-1]['Training accuracy']\n",
        "\n",
        "  print(test_accuracy)\n",
        "\n",
        "  if train_accuracy * .95 > test_accuracy :\n",
        "    print(\"MOST LIKELY OVERFIT\")\n",
        "    num_of_layers += 1\n",
        "    nodes_per_layer += 5\n",
        "  elif test_accuracy < 99:#CustumCallback.min_accuracy:\n",
        "    print(\"NOT TESTING HIGH ENOUGH ACCURACY\")\n",
        "    num_of_layers += 1\n",
        "    nodes_per_layer += 5\n",
        "  else: print(\"This is good\")\n",
        "  \n",
        "  return num_of_layers,nodes_per_layer,activation_function,L2_lambda,Dropout_rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G48uC8OTiiH4"
      },
      "source": [
        "Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAs4osIsijNg",
        "outputId": "e2fa46f6-38a9-4007-b8af-b2e33ace808a"
      },
      "source": [
        "Index_of_network = 0\n",
        "ALL_NETWORKS = []\n",
        "List_of_models = []\n",
        "num_output_nuerons = len(pd.unique(y))\n",
        "num_input_nuerons = X.shape[1]\n",
        "num_of_layers = 10\n",
        "nodes_per_layer = 100\n",
        "activation_function = \"sigmoid\"\n",
        "L2_lambda = 0\n",
        "Dropout_rate = 0\n",
        "\n",
        "def setup(file_name):\n",
        "  load_libraries()\n",
        "  setup_data(file_name)\n",
        "\n",
        "def create_network(num_of_layers,nodes_per_layer,activation_function,L2_lambda,Dropout_rate):\n",
        "  build(num_of_layers,nodes_per_layer,activation_function,L2_lambda,Dropout_rate)\n",
        "  train()\n",
        "  evaluateNN()\n",
        "\n",
        "setup('/content/drive/MyDrive/High School Ramaz/Meta-AI/Files/train.csv')\n",
        "for i in range(3):\n",
        "  create_network(num_of_layers,nodes_per_layer,activation_function,L2_lambda,Dropout_rate)\n",
        "  num_of_layers,nodes_per_layer,activation_function,L2_lambda,Dropout_rate = analyze(num_of_layers,nodes_per_layer,activation_function,L2_lambda,Dropout_rate)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0012 - accuracy: 0.9999\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1362 - accuracy: 0.9692\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5414 - accuracy: 0.9028\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1701 - accuracy: 0.9625\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0821 - accuracy: 0.9829\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0111 - accuracy: 0.9965\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0025 - accuracy: 0.9995\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0020 - accuracy: 0.9997\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0018 - accuracy: 0.9998\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0014 - accuracy: 0.9998\n",
            "Accuracy consistently over 90.0%, training terminated.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/High School Ramaz/Meta-AI/Files/results/saved_model0/assets\n",
            "NN Training Accuracy: 99.99107142857143\n",
            "tf.Tensor(\n",
            "[[3352    0    0    0    0    0    0    0    0    0]\n",
            " [   0 3780    0    0    0    0    0    0    0    0]\n",
            " [   0    0 3328    0    0    0    0    0    0    0]\n",
            " [   0    0    1 3421    0    0    0    0    0    0]\n",
            " [   0    0    0    0 3272    0    0    0    0    0]\n",
            " [   0    0    0    0    0 3020    0    0    0    0]\n",
            " [   0    0    0    0    0    0 3315    0    0    0]\n",
            " [   0    0    0    0    0    0    0 3481    0    0]\n",
            " [   1    0    0    0    0    0    0    0 3257    0]\n",
            " [   0    0    0    1    0    0    0    0    0 3371]], shape=(10, 10), dtype=int32)\n",
            "NN Testing Accuracy: 95.97619047619048\n",
            "tf.Tensor(\n",
            "[[763   0   2   0   1   1   4   0   3   6]\n",
            " [  0 891   2   0   2   0   2   3   3   1]\n",
            " [  5   3 815   8   4   0   2   6   5   1]\n",
            " [  2   0  13 884   0   7   1   5  12   5]\n",
            " [  3   2   3   0 765   0   4   5   4  14]\n",
            " [  4   1   0  16   3 727   8   1  11   4]\n",
            " [  6   2   1   0   4   3 803   0   3   0]\n",
            " [  0   1   8   2   5   1   0 882   3  18]\n",
            " [  3   5   4   9   3   7   2   1 766   5]\n",
            " [  3   0   2   7  11   6   0  16   5 766]], shape=(10, 10), dtype=int32)\n",
            "95.97619047619048\n",
            "NOT TESTING HIGH ENOUGH ACCURACY\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.0013 - accuracy: 0.9999\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1523 - accuracy: 0.9646\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5563 - accuracy: 0.9008\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2303 - accuracy: 0.9532\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0363 - accuracy: 0.9903\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0054 - accuracy: 0.9983\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0022 - accuracy: 0.9996\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0017 - accuracy: 0.9998\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0015 - accuracy: 0.9999\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0013 - accuracy: 0.9999\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0012 - accuracy: 0.9999\n",
            "Accuracy consistently over 90.0%, training terminated.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/High School Ramaz/Meta-AI/Files/results/saved_model1/assets\n",
            "NN Training Accuracy: 99.99404761904762\n",
            "tf.Tensor(\n",
            "[[3351    0    0    0    0    0    0    0    1    0]\n",
            " [   0 3780    0    0    0    0    0    0    0    0]\n",
            " [   0    0 3328    0    0    0    0    0    0    0]\n",
            " [   0    0    0 3422    0    0    0    0    0    0]\n",
            " [   0    0    0    0 3272    0    0    0    0    0]\n",
            " [   0    0    0    0    0 3020    0    0    0    0]\n",
            " [   0    0    0    0    0    0 3315    0    0    0]\n",
            " [   0    0    0    0    0    0    0 3481    0    0]\n",
            " [   0    0    0    1    0    0    0    0 3257    0]\n",
            " [   0    0    0    0    0    0    0    0    0 3372]], shape=(10, 10), dtype=int32)\n",
            "NN Testing Accuracy: 95.89285714285715\n",
            "tf.Tensor(\n",
            "[[762   0   2   0   0   2   4   0   5   5]\n",
            " [  0 890   2   0   1   1   2   5   2   1]\n",
            " [  2   3 813  10   3   0   1   6   7   4]\n",
            " [  2   2  15 878   0   8   0   5  13   6]\n",
            " [  3   2   4   1 761   1   6   4   6  12]\n",
            " [  3   1   0  10   4 728   6   1  16   6]\n",
            " [  4   2   3   0   3   3 804   0   3   0]\n",
            " [  1   1   5   4   5   1   0 880   4  19]\n",
            " [  3   2   6   7   1   7   2   0 773   4]\n",
            " [  3   0   2   8  13   3   0  15   6 766]], shape=(10, 10), dtype=int32)\n",
            "95.89285714285715\n",
            "NOT TESTING HIGH ENOUGH ACCURACY\n",
            "Epoch 1/1000\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.0012 - accuracy: 0.9999\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2600 - accuracy: 0.9480\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4958 - accuracy: 0.9145\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1564 - accuracy: 0.9652\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0362 - accuracy: 0.9906\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0052 - accuracy: 0.9986\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0027 - accuracy: 0.9994\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0021 - accuracy: 0.9997\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0018 - accuracy: 0.9998\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0016 - accuracy: 0.9998\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0015 - accuracy: 0.9999\n",
            "Accuracy consistently over 90.0%, training terminated.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/High School Ramaz/Meta-AI/Files/results/saved_model2/assets\n",
            "NN Training Accuracy: 99.98511904761904\n",
            "tf.Tensor(\n",
            "[[3352    0    0    0    0    0    0    0    0    0]\n",
            " [   0 3780    0    0    0    0    0    0    0    0]\n",
            " [   0    0 3328    0    0    0    0    0    0    0]\n",
            " [   0    0    1 3419    0    1    0    0    1    0]\n",
            " [   0    0    0    0 3272    0    0    0    0    0]\n",
            " [   0    0    0    0    0 3020    0    0    0    0]\n",
            " [   0    0    0    0    0    0 3314    0    1    0]\n",
            " [   0    0    0    0    0    0    0 3481    0    0]\n",
            " [   0    0    0    0    0    0    0    0 3258    0]\n",
            " [   0    0    0    1    0    0    0    0    0 3371]], shape=(10, 10), dtype=int32)\n",
            "NN Testing Accuracy: 96.0\n",
            "tf.Tensor(\n",
            "[[766   0   1   0   1   1   3   0   5   3]\n",
            " [  0 889   2   0   2   1   3   2   4   1]\n",
            " [  3   5 813   9   2   0   3   6   7   1]\n",
            " [  3   1  13 883   0   8   0   6   9   6]\n",
            " [  4   2   4   0 764   1   4   5   4  12]\n",
            " [  1   2   1  13   4 729   6   1  14   4]\n",
            " [  4   2   1   0   5   7 801   0   2   0]\n",
            " [  0   2   5   3   2   2   1 886   4  15]\n",
            " [  3   3   5   9   2   7   3   1 765   7]\n",
            " [  3   2   3   8  12   2   0  13   5 768]], shape=(10, 10), dtype=int32)\n",
            "96.0\n",
            "NOT TESTING HIGH ENOUGH ACCURACY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt9H8xxbrFzh",
        "outputId": "2d678bab-65f2-4d2c-c736-2a95bd8c6909"
      },
      "source": [
        "for i in range(len(ALL_NETWORKS)):\n",
        "  print(i, ALL_NETWORKS[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 {'Testing accuracy': 95.97619047619048, 'Training accuracy': 99.99107142857143}\n",
            "1 {'Testing accuracy': 95.89285714285715, 'Training accuracy': 99.99404761904762}\n",
            "2 {'Testing accuracy': 96.0, 'Training accuracy': 99.98511904761904}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXGvVRwlT3Ic"
      },
      "source": [
        "Random Forest (for comparison)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Atxf_AT5lk"
      },
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train,y_train)\n",
        "\n",
        "tra = rf.predict(X_train)\n",
        "tes = rf.predict(X_test)\n",
        "\n",
        "y_hat2 = [list(x).index(max(x)) for x in tra]\n",
        "print(\"RF Training Accuracy:\",100 * accuracy_score(y_train1d, y_hat2))\n",
        "cm2 = tf.math.confusion_matrix(y_train1d,y_hat2)\n",
        "print(cm2)\n",
        "\n",
        "y_hat3 = [list(x).index(max(x)) for x in tes]\n",
        "print(\"RF Testing Accuracy:\",100 * accuracy_score(y_test1d, y_hat3))\n",
        "cm3 = tf.math.confusion_matrix(y_test1d,y_hat3)\n",
        "print(cm3)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}